#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass scrbook
\begin_preamble
% increases link area for cross-references and autoname them
% if you change the document language to e.g. French
% you must change "extrasenglish" to "extrasfrench"
\AtBeginDocument{%
 \renewcommand{\ref}[1]{\mbox{\autoref{#1}}}
}
\def\refnamechanges{%
 \renewcommand*{\equationautorefname}[1]{}
 \renewcommand{\sectionautorefname}{sec.\negthinspace}
 \renewcommand{\subsectionautorefname}{sec.\negthinspace}
 \renewcommand{\subsubsectionautorefname}{sec.\negthinspace}
 \renewcommand{\figureautorefname}{Fig.\negthinspace}
 \renewcommand{\tableautorefname}{Tab.\negthinspace}
}
\@ifpackageloaded{babel}{\addto\extrasenglish{\refnamechanges}}{\refnamechanges}

% in case somebody want to have the label "Equation"
%\renewcommand{\eqref}[1]{Equation~(\negthinspace\autoref{#1})}

% that links to image floats jumps to the beginning
% of the float and not to its caption
\usepackage[figure]{hypcap}

% the pages of the TOC is numbered roman
% and a pdf-bookmark for the TOC is added
\let\myTOC\tableofcontents
\renewcommand\tableofcontents{%
  \frontmatter
  \pdfbookmark[1]{\contentsname}{}
  \myTOC
  \mainmatter }

% makes caption labels bold
% for more info about these settings, see
% http://mirrors.ctan.org/macros/latex/contrib/koma-script/doc/scrguien.pdf
\setkomafont{captionlabel}{\bfseries}
\setcapindent{1em}

% enables calculations
\usepackage{calc}

% fancy page header/footer settings
% for more information see section 9 of
% ftp://www.ctan.org/pub/tex-archive/macros/latex2e/contrib/fancyhdr/fancyhdr.pdf
\renewcommand{\chaptermark}[1]{\markboth{#1}{#1}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}

% increases the bottom float placement fraction
\renewcommand{\bottomfraction}{0.5}

% avoids that floats are placed above its sections
\let\mySection\section\renewcommand{\section}{\suppressfloats[t]\mySection}
\end_preamble
\options intoc,bibliography=totoc,index=totoc,BCOR10mm,captions=tableheading,titlepage,fleqn
\use_default_options true
\master MasterThesisTemplate.lyx
\begin_modules
customHeadersFooters
theorems-ams
theorems-sec
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "lmodern" "default"
\font_sans "lmss" "default"
\font_typewriter "lmtt" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_title "Your title"
\pdf_author "Your name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\branch NoChildDocument
\selected 0
\filename_suffix 0
\color #ff0000
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 2
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Left Header
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
chaptername
\end_layout

\end_inset


\begin_inset space ~
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thechapter
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
rightmark
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Enable page headers and add the chapter to the header line.
\end_layout

\end_inset


\end_layout

\begin_layout Right Header
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
leftmark
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Left Footer
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thepage
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Center Footer

\end_layout

\begin_layout Right Footer
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thepage
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Methods
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Description of statistical and other methods used with references to the
 scientific literature.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
In this chapter, methods used for performing the change point analysis in
 this thesis are explained.
 It first starts by providing general details about Markov chains.
 Later on, the simple Markov switching model feature and more general model
 specifications namely Markov switching autoregressive model are discussed.
 Next three sections are devoted to some methods for estimating the values
 of parameters, predicting a state for a new observation and selecting a
 suitable model for the datasets.
 Another change point method in a non-parametric approach is described.
 Finally, a simulation technique is explained.
\end_layout

\begin_layout Section
Markov chains
\begin_inset CommandInset label
LatexCommand label
name "sec:Markov-chains"

\end_inset


\end_layout

\begin_layout Standard
A Markov chain is a random process which has a property that given on the
 current value, the future is independent of the past.
 A random process 
\begin_inset Formula $X$
\end_inset

 contains random variables 
\begin_inset Formula $X_{t}:\:t\in T$
\end_inset

 indexed by a set of 
\begin_inset Formula $T$
\end_inset

 where 
\begin_inset Formula $T=\{0,1,2,...\}$
\end_inset

 is called a discrete-time process and 
\begin_inset Formula $T=[0,\infty)$
\end_inset

 is called a continuous-time process.
 Let 
\begin_inset Formula $X_{t}$
\end_inset

 be a sequence which has values from a state space 
\begin_inset Formula $S$
\end_inset

.
 The process begins from one of these states and moves to another state.
 The move between state is called a step.
 The process of Markov chains is described here.
\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.214"
key "grimmett2001probability"

\end_inset

 If a process 
\begin_inset Formula $X$
\end_inset

 satisfies the Markov property, the process 
\begin_inset Formula $X$
\end_inset

 is a first order Markov chain
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
P(X_{t}=s|X_{0}=x_{0},X_{1}=x_{1},...,X_{t-1}=x_{t-1})=P(X_{t}=s|X_{t-1}=x_{t-1})
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $t\ge1$
\end_inset

 and 
\begin_inset Formula $s,x_{0},...,x_{t-1}\in S$
\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X_{t}=i$
\end_inset

 then it is said that the chain is being in state 
\begin_inset Formula $i$
\end_inset

 or the chain is in the 
\begin_inset Formula $i$
\end_inset

th state at the 
\begin_inset Formula $t$
\end_inset

th step.
\end_layout

\begin_layout Standard
There are transitions between states which 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
describe the distribution for the next state given the current state
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
.
 This evolution of changing from 
\begin_inset Formula $X_{t}=i$
\end_inset

 to 
\begin_inset Formula $X_{t}=j$
\end_inset

 is defined by the transition probability 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
as 
\begin_inset Formula $P(X_{t}=j|X_{t-1}=i)$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 Markov chains are frequently assumed that these probabilities depend only
 on 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 and do not depend on 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.214"
key "grimmett2001probability"

\end_inset

 The chain is time-homogeneous if
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
P(X_{t+1}=j|X_{t}=i)=P(X_{1}=j|X_{0}=i)
\]

\end_inset


\end_layout

\begin_layout Definition
for all 
\begin_inset Formula $t,i,j$
\end_inset

.
 The probability of the transition is independent of 
\begin_inset Formula $t$
\end_inset

.
 Then, the transition matrix 
\begin_inset Formula $\mathbf{P}$
\end_inset

 is the matrix of transition probabilities
\end_layout

\begin_layout Definition

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
p_{ij}=P(X_{t}=j|X_{t-1}=i)
\]

\end_inset


\end_layout

\begin_layout Theorem*
\begin_inset CommandInset citation
LatexCommand citep
after "p.215"
key "grimmett2001probability"

\end_inset

 The transition matrix 
\begin_inset Formula $\mathbf{P}$
\end_inset

 is a stochastic matrix that
\end_layout

\begin_deeper
\begin_layout Itemize
Each of the entries is a non-negative real number or 
\begin_inset Formula $p_{ij}\ge0$
\end_inset

 for all 
\begin_inset Formula $i,j$
\end_inset


\end_layout

\begin_layout Itemize
The sum of each column equal to one or 
\begin_inset Formula $\sum_{i}p_{ij}=1$
\end_inset

 for all 
\begin_inset Formula $j$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.222"
key "grimmett2001probability"

\end_inset

 The mean recurrence time of a state 
\begin_inset Formula $i$
\end_inset

 is defined as
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\mu_{i}=E(T_{i}|X=0=i)=\sum_{n}n\cdot f_{ii}(n)
\]

\end_inset


\end_layout

\begin_layout Definition
State 
\begin_inset Formula $i$
\end_inset

 is positive recurrent or non-null persistent if 
\begin_inset Formula $\mu_{i}$
\end_inset

 is finite.
 Otherwise, the state 
\begin_inset Formula $i$
\end_inset

 is null persistent.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.222"
key "grimmett2001probability"

\end_inset

 A state 
\begin_inset Formula $i$
\end_inset

 has the period 
\begin_inset Formula $d(i)$
\end_inset

 and is defined as 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
d(i)=gcd\{n:\:p_{ii}(n)>0\}
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $gcd$
\end_inset

 is the greatest common divisor.
 If 
\begin_inset Formula $d(i)=1$
\end_inset

, then the state is said to be aperiodic.
 Otherwise, the state is said to be periodic.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.222"
key "grimmett2001probability"

\end_inset

 A state is called ergodic if it is non-null persistent and aperiodic.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
A chain is called irreducible if all states are eventually reached from
 any state.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
If there is a finite state space, an irreducible Markov chain is the same
 thing as ergodic Markov chain.
 It is possible to go from every state to every other state with positive
 probability.
 
\end_layout

\begin_layout Section
Markov switching model
\end_layout

\begin_layout Standard
A Markov switching model is used for time series that are evolved over unobserve
d distinct states or regimes.
 This is a regime switching model where the shifting back and forth between
 the regimes is controlled by a latent Markov chain.
 The model structure consists of two stochastic processes embedded in two
 levels of hierarchy.
 One process is an underlying stochastic process that is not observable
 but it is possible to observe them through another stochastic process which
 generated the sequence of observation 
\begin_inset CommandInset citation
LatexCommand citep
key "rabiner1986introduction"

\end_inset

.
 The time of transition to different state and the duration in between is
 random.
 In addition, the state assumes to follow the Markov property that the future
 state depends only on the current state.
 
\end_layout

\begin_layout Standard
The Markov switching model is able to model more complex stochastic processes
 and describes changes in the dynamic behavior.
 A general structure of the model can be drawn in graphically as shown in
 
\begin_inset CommandInset ref
LatexCommand ref
reference "msm"

\end_inset

, where 
\begin_inset Formula $S_{t}$
\end_inset

 and 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $y_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 denote the state sequence and observation sequence in the Markov process,
 respectively.
 The arrows from one state to another state in the diagram implied the condition
al dependency.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/msm.png
	lyxscale 50
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Model structure
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "msm"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The process is given by 
\begin_inset CommandInset citation
LatexCommand citep
key "hamilton1989new"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y_{t}=X_{t}'\beta_{S_{t}}+\varepsilon_{t}\label{eq:msm}
\end{equation}

\end_inset

where 
\begin_inset Formula $y_{t}$
\end_inset

 is the observed value of the time series at time 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $X_{t}$
\end_inset

 are the predictor variables of the time series at time 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula $\beta_{S_{t}}$
\end_inset

 are the coefficients in state 
\begin_inset Formula $S_{t}$
\end_inset

, where 
\begin_inset Formula $S_{t}=i,$
\end_inset

 
\begin_inset Formula $1\leqslant i\leqslant k$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 follows a Normal distribution with mean zero and variance given by 
\begin_inset Formula $\sigma_{S_{t}}^{2}$
\end_inset

 
\end_layout

\begin_layout Standard
The Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:msm"

\end_inset

 is the simplest form for the switching model where there are 
\begin_inset Formula $k-1$
\end_inset

 structural breaks in the model parameters.
 To aid understanding, the baseline model assuming two states 
\begin_inset Formula $(k=2)$
\end_inset

 is discussed.
 
\begin_inset Formula $S_{t}$
\end_inset

 is a random variable which is assumed that the value 
\begin_inset Formula $S_{t}=1$
\end_inset

 for 
\begin_inset Formula $t=1,2,...,t_{0}$
\end_inset

 and 
\begin_inset Formula $S_{t}=2$
\end_inset

 for 
\begin_inset Formula $t=t_{0}+1,t_{0}+2,...,T$
\end_inset

 where 
\begin_inset Formula $t_{0}$
\end_inset

 is a known change point.
 The transition matrix 
\begin_inset Formula $\mathbf{P}$
\end_inset

 is an 
\begin_inset Formula $2\mathrm{x}2$
\end_inset

 matrix where row 
\begin_inset Formula $j$
\end_inset

 column 
\begin_inset Formula $i$
\end_inset

 element is the transition probability 
\begin_inset Formula $p_{ij}$
\end_inset

.
 Since the whole process 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $S_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is unobserved, the initial state
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 where 
\begin_inset Formula $t=0$
\end_inset

 of each state also needs to be specified.
 The probability which describes the starting distribution over states is
 denoted by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi_{i}=P(S_{0}=i)
\]

\end_inset


\end_layout

\begin_layout Standard
There are several options for computing the probability of the initial state.
 One procedure is to simply use a naive guess i.e., setting 
\begin_inset Formula $P(S_{0}=i)=0.5$
\end_inset

.
 Alternatively, the unconditional probability of 
\begin_inset Formula $S_{t}$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi_{1}=P(S_{0}=1)=\frac{1-p_{jj}}{2-p_{ii}-p_{jj}}
\]

\end_inset


\end_layout

\begin_layout Standard
can be used by presuming an ergodic Markov chain 
\begin_inset CommandInset citation
LatexCommand citep
key "hamilton2005regime"

\end_inset

.
\end_layout

\begin_layout Section
Autoregressive (AR) model
\end_layout

\begin_layout Standard
An autoregressive model is one type of time series model that uses for describin
g the time-varying process.
 The model is flexible in handling various kinds of time series patterns.
 The name autoregressive comes from how the model performs a regression
 of the variable against its own previous outputs 
\begin_inset CommandInset citation
LatexCommand citep
key "cryer1986time"

\end_inset

.
 The number of autoregressive lags is denoted by 
\begin_inset Formula $p$
\end_inset

.
 
\end_layout

\begin_layout Definition
An autoregressive model of order 
\begin_inset Formula $p$
\end_inset

 or AR(p) model can be written as 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
y_{t}=c+\phi_{1}y_{t-1}+\phi_{2}y_{t-2}+...+\phi_{p}y_{t-p}+\varepsilon_{t}
\]

\end_inset

or
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
y_{t}=c+\sum_{i=1}^{p}\phi_{i}y_{t-i}+\varepsilon_{t}
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $c$
\end_inset

 is a constant, 
\begin_inset Formula $\phi_{i}$
\end_inset

 are the coefficients in the autoregression and 
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 is Gaussian white noise with zero mean and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $p$
\end_inset

 is equal to one, the model AR(1) is called the first order autoregression
 process.
\end_layout

\begin_layout Section
Markov switching autoregressive model
\end_layout

\begin_layout Standard
This model is an extension of the basic Markov switching model where observation
s are drawn from autoregression process.
 Markov switching autoregressive model relaxes the conditional independent
 assumption by allowing an observation to also depends on a past observation
 and a current state 
\begin_inset CommandInset citation
LatexCommand citep
key "shannon2009formulation"

\end_inset

.
 
\end_layout

\begin_layout Definition
The first order Markov switching autoregressive model is 
\end_layout

\begin_layout Definition

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
y_{t}=X_{t}'\beta_{S_{t}}+\phi_{1,S_{t}}y_{t-1}+\varepsilon_{t}
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $\phi_{1,S_{t}}$
\end_inset

 is the autoregression coefficient of the observed value at time 
\begin_inset Formula $t-1$
\end_inset

 in state 
\begin_inset Formula $S_{t}$
\end_inset

 and 
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 follows a Normal distribution with mean zero and variance given by 
\begin_inset Formula $\sigma_{S_{t}}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
The structure of the model is shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "msm-ar"

\end_inset

.
 It can be clearly seen that there is a dependency at the observation level
 and the observation is not independent from one another.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/msm-ar.png
	lyxscale 50
	scale 70

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Model structure of Markov switching AR(1)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "msm-ar"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Assuming two states 
\begin_inset Formula $S_{t}=1$
\end_inset

 or 
\begin_inset Formula $2$
\end_inset

, the set of parameters for the Markov switching autoregressive model that
 are necessary for describing the law of probability governs 
\begin_inset Formula $y_{t}$
\end_inset

 are 
\begin_inset Formula $\theta=\{\beta_{1},\beta_{2},\phi_{1,1},\phi_{1,2},\sigma_{1}^{2},\sigma_{2}^{2},\pi_{1},\pi_{2},p_{11},p_{22}\}$
\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
Assuming that we do not observe st directly, but only infer its operation
 through the observed behavior of yt, the parameters necessary to fully
 describe the probability law governing yt are 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Parameter estimation
\end_layout

\begin_layout Standard
There are various ways to estimate parameters of Markov switching model.
 Methods which have been widely used are as follow: E-M algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "hamilton1990analysis,kim1994dynamic"

\end_inset

 used the maximum likelihood criterion, Segmental K-mean 
\begin_inset CommandInset citation
LatexCommand citep
key "juang1990segmental"

\end_inset

 used K-means algorithm and maximized the state-optimized likelihood criterion,
 and Gibbs sampling 
\begin_inset CommandInset citation
LatexCommand citep
key "kim1999state"

\end_inset

 used a Markov chain Monte Carlo simulation method based on the Bayesian
 inference.
 In this thesis framework, E-M algorithm is used in estimating parameters
 and is briefly described a general procedure.
 
\end_layout

\begin_layout Subsection
The Expectation-Maximization algorithm
\end_layout

\begin_layout Standard
E-M algorithm is originally designed to deal with the incomplete or missing
 values in data 
\begin_inset CommandInset citation
LatexCommand citep
key "dempster1977maximum"

\end_inset

.
 Nevertheless, it can potentially implement in Markov switching model since
 the unobserved state 
\begin_inset Formula $S_{t}$
\end_inset

 can be viewed as the missing values.
 The set of parameters is estimated by iterative two-step procedure.
 The algorithm starts with an arbitrary initial parameters and finds the
 expected values of the state process given the observations.
 Next, the new maximum likelihood from the derived parameters in previous
 step is calculated.
 These two steps are repeated until the maximum value of the likelihood
 function is reached 
\begin_inset CommandInset citation
LatexCommand citep
key "janczura2012efficient"

\end_inset

.
\end_layout

\begin_layout Subsubsection
E-step
\end_layout

\begin_layout Standard
Assume that 
\begin_inset Formula $\theta^{(n)}$
\end_inset

 is the derived set of parameters in M-step from the previous iteration
 and the available observations of time 
\begin_inset Formula $t-1$
\end_inset

 is denoted as 
\begin_inset Formula $\Omega_{t-1}=(y_{1},y_{2},...,y_{t-1})$
\end_inset

.
 The general idea of this step is to calculate the expectation of 
\begin_inset Formula $S_{t}$
\end_inset

 under the current estimation of the parameters.
 The obtained result is called smoothed inferences probability and is denoted
 by 
\begin_inset Formula $P(S_{t}=j|\Omega_{T};\theta)$
\end_inset

.
 The E-step consists of filtering and smoothing algorithm and the process
 is described as follows 
\begin_inset CommandInset citation
LatexCommand citep
key "kim1994dynamic"

\end_inset

:
\end_layout

\begin_layout Paragraph
Filtering
\end_layout

\begin_layout Standard
Filtered probability is the probability of the non-observable Markov chain
 being in a given state 
\begin_inset Formula $j$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

, conditional on information up to time 
\begin_inset Formula $t$
\end_inset

.
 The algorithm starts from 
\begin_inset Formula $t=1$
\end_inset

 to 
\begin_inset Formula $t=T$
\end_inset

.
 The starting points for the first iteration where 
\begin_inset Formula $t=1$
\end_inset

 is chosen as arbitrary values.
 The probabilities of each state given that the available observation is
 up to time 
\begin_inset Formula $t-1$
\end_inset

 is calculated.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{t-1};\theta^{(n)})=\sum_{i=1}^{k}p_{ij}^{(n)}P(S_{t-1}=i|\Omega_{t-1};\theta^{(n)})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
and the conditional densities of 
\begin_inset Formula $y_{t}$
\end_inset

 given 
\begin_inset Formula $\Omega_{t-1}$
\end_inset

 are
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\begin{equation}
f(y_{t}|\Omega_{t-1};\theta^{(n)})=\sum_{j=1}^{k}f(y_{t}|S_{t}=j,\Omega_{t-1};\theta^{(n)})P(S_{t}=j|\Omega_{t-1};\theta^{(n)})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $f(y_{t}|S_{t}=j,\Omega_{t-1};\theta)=\frac{1}{\sqrt{2\pi\sigma_{S_{t}}^{2}}}exp\left\{ -\frac{(y_{t}-\beta_{S_{t}})^{2}}{2\sigma_{S_{t}}^{2}}\right\} $
\end_inset

 is the likelihood function in each state for time 
\begin_inset Formula $t$
\end_inset

.
 This is simply the Gaussian probability density function.
\end_layout

\begin_layout Standard
Then, with the new observation at time 
\begin_inset Formula $t$
\end_inset

, the probabilities of each state are updated by using Bayes' rule
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{t};\theta^{(n)})=\frac{f(y_{t}|S_{t}=j,\Omega_{t-1};\theta^{(n)})P(S_{t}=j|\Omega_{t-1};\theta^{(n)})}{f(y_{t}|\Omega_{t-1};\theta^{(n)})}\label{eq:fProb}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
It is computing iteratively until all the observation is reached i.e., 
\begin_inset Formula $t=T$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
The joint conditional density function of 
\begin_inset Formula $y_{t},$
\end_inset


\begin_inset Formula $S_{t-1}$
\end_inset

and 
\begin_inset Formula $S_{t}$
\end_inset

 given 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\Omega_{\ensuremath{t-1}}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 are
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
f(y_{t},S_{t-1}=i,S_{t}=j|\Omega_{t-1};\theta^{(n)})=f(y_{t}|S_{t-1}=i,S_{t=}j,\Omega_{t-1};\theta^{(n)})P(S_{t-1}=i,S_{t}=j|\Omega_{t-1};\theta^{(n)})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
and 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
P(S_{t-1}=i,S_{t}=j|\Omega_{t};\theta^{(n)})=\frac{f(y_{t},S_{t-1}=i,S_{t}=j|\Omega_{t-1};\theta^{(n)})}{f(y_{t}|\Omega_{t-1};\theta^{(n)})}
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Smoothing
\end_layout

\begin_layout Standard
Smoothed probability is the probability of the non-observable Markov chain
 being in state 
\begin_inset Formula $j$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

, conditional on all available information.
 The algorithm iterates over 
\begin_inset Formula $t=T-1,T-2,...,1$
\end_inset

.
 The starting values are obtained from the final iteration of the filtered
 probabilities.
\end_layout

\begin_layout Standard
By nothing that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
P(S_{t}=j|S_{t+1}=i,\Omega_{T};\theta^{(n)}) & \thickapprox P(S_{t}=j|S_{t+1}=i,\Omega_{t};\theta^{(n)})\nonumber \\
 & =\frac{P(S_{t}=j,S_{t+1}=i|\Omega_{t};\theta^{(n)})}{P(S_{t+1}=i|\Omega_{t};\theta^{(n)})}\nonumber \\
 & =\frac{P(S_{t}=j|\Omega_{t};\theta^{(n)})p_{ij}^{(n)}}{P(S_{t+1}=i|\Omega_{t};\theta^{(n)})}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
and
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{T};\theta^{(n)})=\sum_{i=1}^{k}P(S_{t}=j,S_{t+1}=i|\Omega_{T};\theta^{(n)})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
Then, the smoothed probabilities can be expressed as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{T};\theta^{(n)})=\sum_{i=1}^{k}\frac{P(S_{t+1}=i|\Omega_{T};\theta^{(n)})P(S_{t}=j|\Omega_{t};\theta^{(n)})p_{ij}^{(n)}}{P(S_{t+1}=i|\Omega_{t};\theta^{(n)})}
\end{equation}

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset

Once the filtered probabilities are estimated, there is necessarily enough
 information to calculate the full log-likelihood function.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\ln L(\theta)=\sum_{t=1}^{T}\ln(f(y_{t}|\Omega_{t-1};\theta^{(n)})=\sum_{t=1}^{T}\ln\sum_{j=1}^{k}((f(y_{t}|S_{t}=j,\Omega_{t-1};\theta^{(n)})P(S_{t}=j|\Omega_{t-1}))\label{eq:loglik}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This is simply a weighted average of the likelihood function in each state.
 The probabilities of states are considered as weights.
\end_layout

\begin_layout Subsubsection
M-step
\end_layout

\begin_layout Standard
The new estimated model parameters 
\begin_inset Formula $\theta^{(n+1)}$
\end_inset

 is obtained by finding the set of parameters that maximizes the Equation
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:loglik"

\end_inset

.
 This new set of parameters is more exact value of the maximum likelihood
 estimates than the previous one.
 It serves as the set of parameters in the next iteration of the E-step.
 The estimated parameters are derived by taking the partial derivative of
 the log-likelihood function with respect to the specific parameter and
 then setting it to zero.
 Generally, this process is similar to the standard maximum likelihood estimatio
n except that it has to be weighted by the smoothed probabilities since
 each observation 
\begin_inset Formula $y_{t}$
\end_inset

 carries probability of coming from any of the 
\begin_inset Formula $k$
\end_inset

 state.
 
\end_layout

\begin_layout Section
State prediction
\end_layout

\begin_layout Standard
A function to predict the most probable state for the new observation is
 implemented in this analysis (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "chap:MSwM-Package"

\end_inset

).
\end_layout

\begin_layout Standard
The probabilities of being in state 
\begin_inset Formula $j$
\end_inset

 at time 
\begin_inset Formula $T+1$
\end_inset

 on the basis of current information are computed by performing the filtering
 algorithm in the E-step of E-M algorithm.
 The filtered probabilities are
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(S_{T+1}=j|\Omega_{T+1};\theta)=\frac{f(y_{T+1}|S_{T+1}=j,\Omega_{T};\theta)P(S_{T+1}=j|\Omega_{T};\theta)}{f(y_{T+1}|\Omega_{T};\theta)}
\]

\end_inset


\end_layout

\begin_layout Standard
This is the Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:fProb"

\end_inset

 where 
\begin_inset Formula $t=T+1$
\end_inset

.
 Then, the new observation at time 
\begin_inset Formula $T+1$
\end_inset

 is said to be in the state 
\begin_inset Formula $j$
\end_inset

 if it has the highest probability.
\end_layout

\begin_layout Section
Model selection
\end_layout

\begin_layout Standard
Model selection is a task of selecting the most suitable model for a given
 set of data based on the quality of the model.
 In this thesis framework, the Bayesian Information Criterion (BIC) is widely
 employed in the applied literature and proved to be useful in selecting
 the model among a finite set of models.
 It is also known as Schwarz Information Criterion 
\begin_inset CommandInset citation
LatexCommand citep
key "schwarz1978estimating"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{BIC}=-2\ln(L(\hat{\theta}))+m\cdot\ln(T)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $L(\hat{\theta})$
\end_inset

 represents the maximized value of the likelihood function,
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\begin_inset Formula $T$
\end_inset

 is the number of observations and 
\begin_inset Formula $m$
\end_inset

 is the number of parameters to be estimated in the model.
 One benefit from using BIC is that this criterion heavily penalizes model
 complexity as it takes into account the number of parameters in the model.
 BIC attempts to reduce the risk of over-fitting.
\end_layout

\begin_layout Section
Non-parametric analysis
\end_layout

\begin_layout Standard
The parametric test statistics outperform the non-parametric test if data
 belongs to some known distribution families.
 However, the parametric test is not properly performing well in detecting
 change point for an unknown underlying distribution 
\begin_inset CommandInset citation
LatexCommand citep
key "sharkey2014nonparametric"

\end_inset

.
 Applying the non-parametric analysis to the real-world process gives a
 real advantage to the analysis since data collected from application, in
 general, does not always have a well-defined structure and prefer such
 analysis that is not too restricted 
\begin_inset CommandInset citation
LatexCommand citep
key "hawkins2010nonparametric"

\end_inset

.
 For this reason, the non-parametric analysis is implemented in order to
 get a heuristic idea of the change point location in this thesis framework.
 The obtained result is also used for comparing with the result from the
 Markov switching autoregressive model.
\end_layout

\begin_layout Subsubsection*
E-divisive
\end_layout

\begin_layout Standard
The 
\emph on
ecp
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
https://cran.r-project.org/web/packages/ecp/index.html
\end_layout

\end_inset

 is an extension package in R which mainly focuses on computing the non-parametr
ic test for multiple change point analysis.
 This change point method is applicable to both univariate and multivariate
 time series.
 A fundamental idea for the method is based on the hierarchical clustering
 approach 
\begin_inset CommandInset citation
LatexCommand citep
key "james2013ecp"

\end_inset

.
 
\end_layout

\begin_layout Standard
The E-divisive method is an algorithm in the 
\emph on
ecp
\emph default
 package.
 This algorithm performs a divisive clustering in order to estimate the
 multiple change points.
 The E-divisive recursively partitions a time series and estimates a single
 change point in each iteration.
 Consequently, the new change point is located at each iteration and it
 divides the time series into different segments.
 The algorithm also used a permutation test to compute the statistical significa
nce of an estimated change point.
 More details about the estimation is described on 
\begin_inset CommandInset citation
LatexCommand citet
key "matteson2014nonparametric"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
E-agglomerative
\end_layout

\begin_layout Plain Layout
The E-agglomerative algorithm performs an agglomerative clustering in favor
 of estimating the multiple change points.
 The algorithm tries to maximize a goodness of fit test after merging segments
 in the iteration.
 The estimated change point is defined by the iteration that maximized a
 goodness of fit statistic.
 This algorithm allows users to input an initial segmentation for the time
 series or a prior knowledge of the possible change point in order to reduce
 the computation time.
 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Simulation 
\end_layout

\begin_layout Standard
Since there is no annotation for the state of the CPU utilization in the
 data, an accuracy can not be computed after making a state prediction.
 One possible solution to test and verify how well the implemented predict
 function performs is to use the simulation technique.
 Therefore, a data consists of two predictor variables and one response
 variable with the known state is simulated.
 The actual models for each state are 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y=\begin{cases}
\begin{array}{c}
10+0.6X1_{t}-0.9X2_{t}+0.5Y_{t-1}+\varepsilon_{t}^{(1)}\\
2+0.8X1_{t}+0.2Y_{t-1}+\varepsilon_{t}^{(2)}\\
-12+0.7X1_{t}+0.2Y_{t-1}+\varepsilon_{t}^{(3)}
\end{array} & \begin{array}{c}
\varepsilon_{t}^{(1)}\sim N(0,1)\\
\varepsilon_{t}^{(2)}\sim N(2,0.5)\\
\varepsilon_{t}^{(3)}\sim N(1,1)
\end{array}\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
The data contains 500 observations which has a presence of three different
 states – Normal, Bad and Good.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sim_data"

\end_inset

 presents a plot of 
\begin_inset Formula $y$
\end_inset

 over a period of time and the period where observations in the data belong
 to one of the state is shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sim_state"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/sim_data.png
	lyxscale 50
	scale 40

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Simulated data.
 The 
\begin_inset Formula $y$
\end_inset

 variable is the response variable
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sim_data"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/sim_state.png
	lyxscale 30
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The period in the time series when data is in each state 
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sim_state"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Comment
status open

\begin_layout Plain Layout
COMBINE PLOT
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Branch NoChildDocument
status collapsed

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "thesisExample"
options "alpha"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomencl_print
LatexCommand printnomenclature
set_width "custom"
width "2.5cm"

\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
