#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass scrbook
\begin_preamble
% increases link area for cross-references and autoname them
% if you change the document language to e.g. French
% you must change "extrasenglish" to "extrasfrench"
\AtBeginDocument{%
 \renewcommand{\ref}[1]{\mbox{\autoref{#1}}}
}
\def\refnamechanges{%
 \renewcommand*{\equationautorefname}[1]{}
 \renewcommand{\sectionautorefname}{sec.\negthinspace}
 \renewcommand{\subsectionautorefname}{sec.\negthinspace}
 \renewcommand{\subsubsectionautorefname}{sec.\negthinspace}
 \renewcommand{\figureautorefname}{Fig.\negthinspace}
 \renewcommand{\tableautorefname}{Tab.\negthinspace}
}
\@ifpackageloaded{babel}{\addto\extrasenglish{\refnamechanges}}{\refnamechanges}

% in case somebody want to have the label "Equation"
%\renewcommand{\eqref}[1]{Equation~(\negthinspace\autoref{#1})}

% that links to image floats jumps to the beginning
% of the float and not to its caption
\usepackage[figure]{hypcap}

% the pages of the TOC is numbered roman
% and a pdf-bookmark for the TOC is added
\let\myTOC\tableofcontents
\renewcommand\tableofcontents{%
  \frontmatter
  \pdfbookmark[1]{\contentsname}{}
  \myTOC
  \mainmatter }

% makes caption labels bold
% for more info about these settings, see
% http://mirrors.ctan.org/macros/latex/contrib/koma-script/doc/scrguien.pdf
\setkomafont{captionlabel}{\bfseries}
\setcapindent{1em}

% enables calculations
\usepackage{calc}

% fancy page header/footer settings
% for more information see section 9 of
% ftp://www.ctan.org/pub/tex-archive/macros/latex2e/contrib/fancyhdr/fancyhdr.pdf
\renewcommand{\chaptermark}[1]{\markboth{#1}{#1}}
\renewcommand{\sectionmark}[1]{\markright{\thesection\ #1}}

% increases the bottom float placement fraction
\renewcommand{\bottomfraction}{0.5}

% avoids that floats are placed above its sections
\let\mySection\section\renewcommand{\section}{\suppressfloats[t]\mySection}
\end_preamble
\options intoc,bibliography=totoc,index=totoc,BCOR10mm,captions=tableheading,titlepage,fleqn
\use_default_options true
\master MasterThesisTemplate.lyx
\begin_modules
customHeadersFooters
theorems-ams
theorems-sec
logicalmkup
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "lmodern" "default"
\font_sans "lmss" "default"
\font_typewriter "lmtt" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize 12
\spacing single
\use_hyperref true
\pdf_title "Your title"
\pdf_author "Your name"
\pdf_bookmarks true
\pdf_bookmarksnumbered true
\pdf_bookmarksopen true
\pdf_bookmarksopenlevel 1
\pdf_breaklinks false
\pdf_pdfborder true
\pdf_colorlinks false
\pdf_backref false
\pdf_pdfusetitle false
\pdf_quoted_options "pdfpagelayout=OneColumn, pdfnewwindow=true, pdfstartview=XYZ, plainpages=false"
\papersize a4paper
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\branch NoChildDocument
\selected 0
\filename_suffix 0
\color #ff0000
\end_branch
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 2
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 2
\paperpagestyle fancy
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Left Header
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
chaptername
\end_layout

\end_inset


\begin_inset space ~
\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thechapter
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
rightmark
\end_layout

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Enable page headers and add the chapter to the header line.
\end_layout

\end_inset


\end_layout

\begin_layout Right Header
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
leftmark
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Left Footer
\begin_inset Argument 1
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thepage
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Center Footer

\end_layout

\begin_layout Right Footer
\begin_inset Argument 1
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
thepage
\end_layout

\end_inset


\end_layout

\begin_layout Chapter
Methods
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Description of statistical and other methods used with references to the
 scientific literature.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
This chapter first starts by providing a survey of existing methods that
 address the problem of detecting changes in a system.
 Later on, general information about Markov chains, the simple Markov switching
 model feature, and model specification namely Markov switching autoregressive
 model are discussed.
 Thereafter, three sections are devoted to methods for estimating the values
 of parameters, predicting a state for a new observation, and selecting
 a suitable model for the datasets.
 Another change-point method in a non-parametric approach called the E-divisive
 is described.
 Finally, the simulation technique is explained.
\end_layout

\begin_layout Section
Survey of existing methods
\end_layout

\begin_layout Standard

\emph on
Change point detection, Anomaly detection, Intrusion detection, 
\emph default
or 
\emph on
Outlier detection
\emph default
 are terms that are closely related to one another.
 The main idea of these terms is to identify and discover events that are
 abnormal from the usual behavior.
 There are several methods to address these types of problem.
 A survey of existing methods has been done in the thesis, and some methods
 are presented in this section.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citet
key "valdes2000adaptive"

\end_inset

 employed a Bayesian inference technique, specifically a naive Bayesian
 network, to create an intrusion detection system on traffic bursts.
 Even though the Bayesian network is effective in detecting anomalies in
 some applications, there are some limitations that should be considered
 when using this method.
 As accuracy of a detection system depends heavily on certain assumptions,
 the system will have low accuracy if an inaccurate model is implemented
 
\begin_inset CommandInset citation
LatexCommand citep
key "patcha2007overview"

\end_inset

.
\end_layout

\begin_layout Standard
Support vector machine (SVM) introduced in 
\begin_inset CommandInset citation
LatexCommand citet
key "cortes1995support"

\end_inset

 is a supervised learning algorithm to deal with a classification analysis
 problem by using the idea of separating hyperplanes.
 The main reason that SVM is used in anomaly detection is because of its
 speed and scalability 
\begin_inset CommandInset citation
LatexCommand citep
key "sung2003identifying"

\end_inset

.
 Although this method is effective in identifying new kinds of anomalies,
 the method often has a higher rate of false alarms due to the fact that
 the SVM method ignores the relationships and dependencies between the features
 
\begin_inset CommandInset citation
LatexCommand citep
key "sarasamma2005hierarchical"

\end_inset

.
 
\end_layout

\begin_layout Standard
Self-organizing maps (SOM) developed by 
\begin_inset CommandInset citation
LatexCommand citet
key "kohonen1982self"

\end_inset

 is a well-known unsupervised neural network approach for cluster analysis.
 SOM is efficient in handling large and high dimensional datasets.
 
\begin_inset CommandInset citation
LatexCommand citet
key "nousiainen2009anomaly"

\end_inset

 used SOM for an anomaly detection in a server log data.
 The study presented an ability of the SOM method in detecting anomalies
 in the data, and also compared the results from the SOM method with a threshold
 based system.
 A disadvantage of the SOM is that initial weight vector affects a performance
 of the SOM, which leads to an unstable clustering result.
 Besides, if the anomalies in the data tend to form clusters, this method
 will not be able to detect these anomalies 
\begin_inset CommandInset citation
LatexCommand citep
key "chandola2009anomaly"

\end_inset

.
 
\end_layout

\begin_layout Standard
Based on previous works, the Hidden Markov model or the Markov switching
 model has also been used in identifying changes and anomalies.
 One drawback from the method based on the Markov chain is that the method
 has a high computational cost, which is not scalable for an online change
 application 
\begin_inset CommandInset citation
LatexCommand citep
key "patcha2007overview"

\end_inset

.
 Apart from changes that can be detected in the data, some knowledge about
 the unobservable condition of the system can also be obtained.
 This additional information makes the method more appealing than the other
 methods.
 Therefore, the Markov switching model is implemented in this thesis framework.
 
\begin_inset Note Comment
status open

\begin_layout Plain Layout
A hidden Markov model’s states represent some unobservable condition of
 the sys- tem being modeled.
 In each state, there is a certain probability of producing any of the observabl
e system outputs and a separate probability indicating the likely next states.
 By having different output probability distributions in each of the states,
 and allowing the system to change states over time, the model is capable
 of representing non-stationary sequences.
\end_layout

\end_inset


\end_layout

\begin_layout Section
Markov chains
\begin_inset CommandInset label
LatexCommand label
name "sec:Markov-chains"

\end_inset


\end_layout

\begin_layout Standard
A Markov chain is a random process which has a property that is given the
 current value, the future is independent of the past.
 A random process 
\begin_inset Formula $X$
\end_inset

 contains random variables 
\begin_inset Formula $X_{t}:\:t\in T$
\end_inset

 indexed by a set 
\begin_inset Formula $T$
\end_inset

.
 When 
\begin_inset Formula $T=\{0,1,2,...\}$
\end_inset

 the process is called a discrete-time process, and when 
\begin_inset Formula $T=[0,\infty)$
\end_inset

 it is called a continuous-time process.
 Let 
\begin_inset Formula $X_{t}$
\end_inset

 be a sequence of values from a state space 
\begin_inset Formula $S$
\end_inset

.
 The process begins from one of these states and moves to another state.
 The move between states is called a step.
 The process of Markov chains is described here.
\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.214"
key "grimmett2001probability"

\end_inset

 If a process 
\begin_inset Formula $X$
\end_inset

 satisfies the Markov property, the process 
\begin_inset Formula $X$
\end_inset

 is a first order Markov chain
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
P(X_{t}=s|X_{0}=x_{0},X_{1}=x_{1},...,X_{t-1}=x_{t-1})=P(X_{t}=s|X_{t-1}=x_{t-1})
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $t\ge1$
\end_inset

 and 
\begin_inset Formula $s,x_{0},...,x_{t-1}\in S$
\end_inset


\end_layout

\begin_layout Standard
If 
\begin_inset Formula $X_{t}=i$
\end_inset

 then the chain is in state 
\begin_inset Formula $i$
\end_inset

 or the chain is in the 
\begin_inset Formula $i$
\end_inset

th state at the 
\begin_inset Formula $t$
\end_inset

th step.
 
\end_layout

\begin_layout Standard
There are transitions between states which 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
describe the distribution of the next state given the current state
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
.
 The evolution of changing from 
\begin_inset Formula $X_{t}=i$
\end_inset

 to 
\begin_inset Formula $X_{t}=j$
\end_inset

 is defined as the transition probability
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 
\begin_inset Formula $P(X_{t}=j|X_{t-1}=i)$
\end_inset

.

\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 For Markov chains, it is frequently assumed that these probabilities depend
 only on 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $j$
\end_inset

 and do not depend on 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.214"
key "grimmett2001probability"

\end_inset

 A Markov chain is time-homogeneous if
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
P(X_{t+1}=j|X_{t}=i)=P(X_{1}=j|X_{0}=i)
\]

\end_inset


\end_layout

\begin_layout Definition
for all 
\begin_inset Formula $t,i,j$
\end_inset

.
 The probability of the transition is independent of 
\begin_inset Formula $t$
\end_inset

.
 A 
\emph on
transition matrix
\emph default
 
\begin_inset Formula $\mathbf{P}=(p_{ij})$
\end_inset

 is a matrix of transition probabilities 
\end_layout

\begin_layout Definition

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
p_{ij}=P(X_{t}=j|X_{t-1}=i)\qquad\mathrm{for}\,\mathrm{all\,}t,i,j
\]

\end_inset


\end_layout

\begin_layout Theorem*
\begin_inset CommandInset citation
LatexCommand citep
after "p.215"
key "grimmett2001probability"

\end_inset

 The transition matrix 
\begin_inset Formula $\mathbf{P}$
\end_inset

 is a matrix that
\end_layout

\begin_deeper
\begin_layout Itemize
Each of the entries is a non-negative real number or 
\begin_inset Formula $p_{ij}\ge0$
\end_inset

 for all 
\begin_inset Formula $i,j$
\end_inset


\end_layout

\begin_layout Itemize
The sum of each row equal to one or 
\begin_inset Formula $\sum_{j}p_{ij}=1$
\end_inset

 for all 
\begin_inset Formula $i$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.227"
key "grimmett2001probability"

\end_inset

 The vector 
\begin_inset Formula $\pi$
\end_inset

 is called a stationary distribution if 
\begin_inset Formula $\pi$
\end_inset

 has entries 
\begin_inset Formula $(\pi_{j}:\:j\in S)$
\end_inset

 that satisfies
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Formula $\pi_{j}\geq0$
\end_inset

 for all 
\begin_inset Formula $j$
\end_inset

, and 
\begin_inset Formula $\sum_{j}\pi_{j}=1$
\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $\pi=\pi\mathbf{P}$
\end_inset

, which is 
\begin_inset Formula $\pi_{j}=\sum_{i}\pi_{i}p_{ij}$
\end_inset

for all 
\begin_inset Formula $j$
\end_inset


\end_layout

\end_deeper
\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.220"
key "grimmett2001probability"

\end_inset

 A state 
\begin_inset Formula $i$
\end_inset

 is called persistent (or recurrent) if
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
P(X_{t}=i\mathrm{\:for\,}\mathrm{some\,\mathrm{t}}\geq1|X_{0}=i)=1
\]

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Let 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $f_{ij}(t)=P(X_{1}\neq j,X_{2}\neq j,...,X_{t}=j|X_{0}=i)$
\end_inset

 be the probability of visiting state 
\begin_inset Formula $j$
\end_inset

 first by starting from 
\begin_inset Formula $i$
\end_inset

, takes place at 
\begin_inset Formula $t$
\end_inset

th step.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.222"
key "grimmett2001probability"

\end_inset

 The mean recurrence time of a persistent state 
\begin_inset Formula $i$
\end_inset

 is defined as
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
\mu_{i}=E(T_{i}|X_{0}=i)=\sum_{n}n\cdot f_{ii}(n)
\]

\end_inset


\end_layout

\begin_layout Definition
State 
\begin_inset Formula $i$
\end_inset

 is a non-null persistent (or positive recurrent) if 
\begin_inset Formula $\mu_{i}$
\end_inset

 is finite.
 Otherwise, the state 
\begin_inset Formula $i$
\end_inset

 is null persistent.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.222"
key "grimmett2001probability"

\end_inset

 The period 
\begin_inset Formula $d(i)$
\end_inset

 of a state 
\begin_inset Formula $i$
\end_inset

 is defined as 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
d(i)=gcd\{n:\:p_{ii}(n)>0\}
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $gcd$
\end_inset

 is the greatest common divisor.
 If 
\begin_inset Formula $d(i)=1$
\end_inset

, then the state is said to be aperiodic.
 Otherwise, the state is said to be periodic.
 
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
\begin_inset CommandInset citation
LatexCommand citep
after "p.222"
key "grimmett2001probability"

\end_inset

 A state is called ergodic if it is non-null persistent and aperiodic.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Definition
A chain is called irreducible if it is possible to go from every state to
 every other states.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Theorem*
If all states in an irreducible Markov chain are ergodic, the chain is said
 to be ergodic.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Theorem*
\begin_inset CommandInset citation
LatexCommand citep
key "manning2008introduction"

\end_inset

 If there is an aperiodic finite state, an irreducible Markov chain is the
 same thing as an ergodic Markov chain.
 
\end_layout

\begin_layout Section
Markov switching model
\end_layout

\begin_layout Standard
A Markov switching model is a switching model where the shifting back and
 forth between the states or regimes is controlled by a latent Markov chain.
 The model structure consists of two stochastic processes embedded in two
 levels of hierarchy.
 One process is an underlying stochastic process that is not normally observable
, but possible to be observed through another stochastic process which generates
 the sequence of observation 
\begin_inset CommandInset citation
LatexCommand citep
key "rabiner1986introduction"

\end_inset

.
 The transition time between two states is random.
 In addition, the state transitions are assumed to follow the Markov property
 that the future state depends only on the current state.
 
\end_layout

\begin_layout Standard
The Markov switching model is able to model more complex stochastic processes
 and describe changes in the dynamic behavior.
 A general structure of the model can be drawn graphically as shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "msm"

\end_inset

, where 
\begin_inset Formula $S_{t}$
\end_inset

 and 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $y_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 denote the state sequence and observation sequence in the Markov process,
 respectively.
 The arrows from one state to another state in the diagram implies a conditional
 dependency.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/msm1.png
	lyxscale 50
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Model structure
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "msm"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The process is given by 
\begin_inset CommandInset citation
LatexCommand citep
key "hamilton1989new"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y_{t}=X_{t}\beta_{S_{t}}+\varepsilon_{t}\label{eq:general_mswm}
\end{equation}

\end_inset

where, 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $y_{t}$
\end_inset

 is an observed value of the time series at time 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $X_{t}$
\end_inset

 is a design matrix, also known as model matrix, containing values of predictor
 variables of the time series at time 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\beta_{S_{t}}$
\end_inset

 are a column vector of coefficients in state 
\begin_inset Formula $S_{t}$
\end_inset

, where 
\begin_inset Formula $S_{t}\in\{1,...,k\}$
\end_inset

 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 follows a normal distribution with zero mean and variance given by 
\begin_inset Formula $\sigma_{S_{t}}^{2}$
\end_inset

 
\end_layout

\begin_layout Standard
Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:general_mswm"

\end_inset

 is the simplest form for the switching model.
 To aid understanding, the baseline model is assumed to have only two states
 
\begin_inset Formula $(k=2)$
\end_inset

 in this discussion.
 
\begin_inset Formula $S_{t}$
\end_inset

 is a random variable which is assumed that the value 
\begin_inset Formula $S_{t}=1$
\end_inset

 for 
\begin_inset Formula $t=1,2,...,t_{0}$
\end_inset

 and 
\begin_inset Formula $S_{t}=2$
\end_inset

 for 
\begin_inset Formula $t=t_{0}+1,t_{0}+2,...,T$
\end_inset

 where 
\begin_inset Formula $t_{0}$
\end_inset

 is a known change point.
 
\end_layout

\begin_layout Standard
The transition matrix 
\begin_inset Formula $\mathbf{P}$
\end_inset

 is an 
\begin_inset Formula $2\mathrm{x}2$
\end_inset

 matrix where row 
\begin_inset Formula $j$
\end_inset

 column 
\begin_inset Formula $i$
\end_inset

 element is the transition probability 
\begin_inset Formula $p_{ij}$
\end_inset

.
 A diagram showing a state-transition is shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "transition"

\end_inset

.
 Note that these probabilities are independent of 
\begin_inset Formula $t$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/transition.png
	lyxscale 50
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
State-transition diagram
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "transition"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Since the whole process 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $S_{t}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 is unobserved, the initial state
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
 where 
\begin_inset Formula $t=0$
\end_inset

 also needs to be specified.
 The probability which describes the starting distribution over states is
 denoted by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi_{i}=P(S_{0}=i)
\]

\end_inset


\end_layout

\begin_layout Standard
There are several options for choosing the probability of the initial state.
 One procedure is to commonly set 
\begin_inset Formula $P(S_{0}=i)=0.5$
\end_inset

.
 Alternatively, by presuming an ergodic Markov chain 
\begin_inset CommandInset citation
LatexCommand citep
key "hamilton2005regime"

\end_inset

, the initial state which is a stationary distribution is defined as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\pi_{i}=P(S_{0}=i)=\frac{1-p_{jj}}{2-p_{ii}-p_{jj}}
\]

\end_inset


\end_layout

\begin_layout Standard
This is simply from solving the system of equations 
\begin_inset Formula $\pi=\pi\mathbf{P}$
\end_inset

.
\end_layout

\begin_layout Proof
Let 
\begin_inset Formula $\pi=(\pi_{1},\pi_{2})'$
\end_inset

 and 
\begin_inset Formula $\mathbf{P}=\left[\begin{array}{cc}
p_{ii} & 1-p_{ii}\\
1-p_{jj} & p_{jj}
\end{array}\right]$
\end_inset


\end_layout

\begin_layout Proof
From
\begin_inset Formula 
\[
\pi=\pi\mathbf{P}
\]

\end_inset


\end_layout

\begin_layout Proof
Then,
\begin_inset Formula 
\begin{align*}
\pi_{1} & =\pi_{1}p_{ii}+\pi_{2}(1-p_{jj})\\
\pi_{2} & =\pi_{1}(1-p_{ii})+\pi_{2}p_{jj}
\end{align*}

\end_inset


\end_layout

\begin_layout Proof
Therefore,
\begin_inset Formula 
\begin{equation}
\pi_{2}=\frac{\pi_{1}(1-p_{ii})}{1-p_{jj}}\label{eq:1}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
and
\begin_inset Formula 
\begin{equation}
\pi_{1}+\pi_{2}=1\label{eq:2}
\end{equation}

\end_inset


\end_layout

\begin_layout Proof
Then, substitute 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:1"

\end_inset

 into 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:2"

\end_inset


\begin_inset Formula 
\[
\pi_{1}=\frac{1-p_{jj}}{2-p_{ii}-p_{jj}}
\]

\end_inset


\end_layout

\begin_layout Standard
A coefficient of a predictor variable in the Markov switching model can
 have either different values in different state or a constant value in
 all state.
 The variable which have the former behavior is said to have a 
\emph on
switching effect
\emph default
.
 Likewise, the variable which have the same coefficient in all states is
 the variable that does not have a switching effect, or said to have a 
\emph on
non-switching effect.

\emph default
 
\end_layout

\begin_layout Standard
A generalized form of Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:general_mswm"

\end_inset

 can be defined as 
\begin_inset CommandInset citation
LatexCommand citep
key "perlin2015ms_regress"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
y_{t}=X_{t}^{ns}\alpha_{t}+X_{t}^{s}\beta_{S_{t}}+\varepsilon_{t}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where, 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $X_{t}^{ns}$
\end_inset

 contains all predictor variables that have non-switching effect of the
 time series at time 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\alpha_{t}$
\end_inset

 are non-switching coefficients of the time series at time 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $X_{t}^{s}$
\end_inset

 contains all predictor variables that have the switching effect of the
 time series at time 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula $\beta_{S_{t}}$
\end_inset

 
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
are switching coefficients in state 
\begin_inset Formula $S_{t}$
\end_inset

, where 
\begin_inset Formula $S_{t}\in\{1,...,k\}$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 follows a normal distribution with zero mean and variance given by 
\begin_inset Formula $\sigma_{S_{t}}^{2}$
\end_inset

 
\end_layout

\begin_layout Subsection
Autoregressive (AR) model
\end_layout

\begin_layout Standard
An autoregressive model is one type of time series models used to describe
 a time-varying process.
 The model is flexible in handling various kinds of time series patterns.
 The name autoregressive comes from how the model performs a regression
 of the variable against its own previous outputs 
\begin_inset CommandInset citation
LatexCommand citep
key "cryer1986time"

\end_inset

.
 The number of autoregressive lags (i.e., the number of prior values used
 in the model) is denoted by 
\begin_inset Formula $p$
\end_inset

.
 
\end_layout

\begin_layout Definition
An autoregressive model of order 
\begin_inset Formula $p$
\end_inset

 or AR(p) model can be written as 
\end_layout

\begin_layout Definition
\begin_inset Formula 
\[
y_{t}=c+\sum_{i=1}^{p}\phi_{i}y_{t-i}+\varepsilon_{t}
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $c$
\end_inset

 is a constant, 
\begin_inset Formula $\phi_{i}$
\end_inset

 are coefficients in the autoregression and 
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 follows a normal distribution with zero mean and variance 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
If 
\begin_inset Formula $p$
\end_inset

 is equal to one, the model AR(1) is called the first order autoregression
 process.
\end_layout

\begin_layout Subsection
Markov switching autoregressive model
\end_layout

\begin_layout Standard
A Markov switching autoregressive model is an extension of a basic Markov
 switching model where observations are drawn from an autoregressive process.
 The model relaxes the conditional independence assumption by allowing an
 observation to depend on both past observation and a current state 
\begin_inset CommandInset citation
LatexCommand citep
key "shannon2009formulation"

\end_inset

.
 Basically, this is the combination between the Markov switching model and
 the autoregressive model.
\end_layout

\begin_layout Definition
The first order Markov switching autoregressive model is 
\end_layout

\begin_layout Definition

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\[
y_{t}=X_{t}\beta_{S_{t}}+\phi_{1,S_{t}}y_{t-1}+\varepsilon_{t}
\]

\end_inset


\end_layout

\begin_layout Definition
where 
\begin_inset Formula $\phi_{1,S_{t}}$
\end_inset

 is an autoregressive coefficient of the observed value at time 
\begin_inset Formula $t-1$
\end_inset

 in state 
\begin_inset Formula $S_{t}$
\end_inset

.
 
\begin_inset Formula $\varepsilon_{t}$
\end_inset

 follows a normal distribution with zero mean and variance given by 
\begin_inset Formula $\sigma_{S_{t}}^{2}$
\end_inset

.
\end_layout

\begin_layout Standard
The structure of the model is shown in 
\begin_inset CommandInset ref
LatexCommand ref
reference "msm-ar"

\end_inset

.
 It can be clearly seen that there is a dependency at the observation level.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/msm-ar1.png
	lyxscale 50
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Model structure of Markov switching AR(1)
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "msm-ar"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Assuming two states 
\begin_inset Formula $S_{t}=1$
\end_inset

 or 
\begin_inset Formula $2$
\end_inset

, the set of parameters that are necessary to describe the law of probability
 that governs 
\begin_inset Formula $y_{t}$
\end_inset

 are 
\begin_inset Formula $\theta=\{\beta_{1},\beta_{2},\phi_{1,1},\phi_{1,2},\sigma_{1}^{2},\sigma_{2}^{2},\pi_{1},\pi_{2},p_{11},p_{22}\}$
\end_inset

.
 
\end_layout

\begin_layout Standard
For the simplicity, in this thesis, the term Markov switching autoregressive
 model will be addressed as the Markov switching model.
\end_layout

\begin_layout Section
Parameter estimation
\end_layout

\begin_layout Standard
There are various ways to estimate parameters of a Markov switching model.
 Methods which have been widely used are as follows: E-M algorithm 
\begin_inset CommandInset citation
LatexCommand citep
key "hamilton1990analysis,kim1994dynamic"

\end_inset

 uses the maximum likelihood criterion, Segmental K-means 
\begin_inset CommandInset citation
LatexCommand citep
key "juang1990segmental"

\end_inset

 uses K-means algorithm and maximizes the state-optimized likelihood criterion,
 and Gibbs sampling 
\begin_inset CommandInset citation
LatexCommand citep
key "kim1999state"

\end_inset

 uses a Markov chain Monte Carlo simulation method based on the Bayesian
 inference.
 
\end_layout

\begin_layout Standard
In this thesis framework, the E-M algorithm is used in estimating parameters
 as the algorithm gives effective results, numerically stable, and easy
 to implement.
 
\begin_inset CommandInset citation
LatexCommand citet
key "ryden2008versus"

\end_inset

 compared the computational perspective in estimating parameters between
 the E-M algorithm and the Gibbs sampling.
 In most cases, the Gibbs sampling tended to have less computational time
 than the E-M algorithm.
 However, the study indicated that if the number of states was unknown and
 only point estimate was sufficient, the E-M algorithm would typically be
 simpler and quicker solution in computing the estimated parameters.
 The E-M algorithm is briefly described below.
 
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
Summing up this case, we first remark that if one wants to compute only
 the best model without any further information on how plausible it is relative
 to other ones, then the simplest solution is using EM to compute MLEs for
 all candidate models and then calculating and comparing their BICs or some
 other penalized likelihood criterion.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
The Expectation-Maximization algorithm
\end_layout

\begin_layout Standard
E-M algorithm is originally designed to deal with the problem of incomplete
 or missing values in data 
\begin_inset CommandInset citation
LatexCommand citep
key "dempster1977maximum"

\end_inset

.
 Nevertheless, it could be implemented in Markov switching model since the
 unobserved state 
\begin_inset Formula $S_{t}$
\end_inset

 can be viewed as missing data values.
 
\end_layout

\begin_layout Standard
The set of parameters 
\begin_inset Formula $\theta$
\end_inset

 are estimated by an iterative two-step procedure.
 In the first step, the algorithm starts with arbitrary initial parameters,
 and then finds
\begin_inset Note Note
status open

\begin_layout Plain Layout
include feed-back of values: hint to the detail in M-step
\end_layout

\end_inset

 the expected values of the state process from the given observations.
 In the second step of the iterative procedure, a new maximum likelihood
 from the derived parameters in the previous step is calculated.
 These two steps are repeated until the maximum value of the likelihood
 function is reached or has converged 
\begin_inset CommandInset citation
LatexCommand citep
key "janczura2012efficient"

\end_inset

.
 The two steps are known as the E-step and the M-step.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "em"

\end_inset

 illustrates the process of the E-M algorithm.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/em.png
	lyxscale 40
	scale 55

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
A flowchart showing the process of the Expectation-Maximization algorithm.
 The algorithm begins with a set of initial values.
 The E-step is performed by computing a filtering and smoothing algorithm.
 Then, the M-step is performed.
 Iterating both steps until convergence.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "em"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
E-step
\end_layout

\begin_layout Standard
In this step, 
\begin_inset Formula $\theta^{(n)}$
\end_inset

 is the derived set of parameters in M-step from the previous iteration,
 and 
\begin_inset Formula $n$
\end_inset

 is a current iteration in the algorithm.
 The available observations of time 
\begin_inset Formula $t-1$
\end_inset

 is denoted as 
\begin_inset Formula $\Omega_{t-1}=(y_{1},y_{2},...,y_{t-1})$
\end_inset

.
 The general idea of this step is to calculate the expectation of 
\begin_inset Formula $S_{t}$
\end_inset

 under the current estimation of the parameters.
 The obtained result is called smoothed inferences probability, and is denoted
 by 
\begin_inset Formula $P(S_{t}=j|\Omega_{T};\theta)$
\end_inset

 where 
\begin_inset Formula $T$
\end_inset

 is the number of all observations in the data and 
\begin_inset Formula $j=1,2,...,k$
\end_inset

.
 The E-step which consists of filtering and smoothing algorithm is described
 as follows 
\begin_inset CommandInset citation
LatexCommand citep
key "kim1994dynamic"

\end_inset

:
\end_layout

\begin_layout Paragraph
Filtering
\end_layout

\begin_layout Standard
A filtered probability is a probability of a non-observable Markov chain
 being in a given state 
\begin_inset Formula $j$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

, conditional on information up to time 
\begin_inset Formula $t$
\end_inset

.
 The algorithm starts from 
\begin_inset Formula $t=1$
\end_inset

 to 
\begin_inset Formula $t=T$
\end_inset

.
 A starting point for the first iteration where 
\begin_inset Formula $t=1$
\end_inset

 is chosen from arbitrary values.
 The probabilities of each state given available observations up to time
 
\begin_inset Formula $t-1$
\end_inset

 is calculated by
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{t-1};\theta^{(n)})=\sum_{i=1}^{k}p_{ij}^{(n)}P(S_{t-1}=i|\Omega_{t-1};\theta^{(n)})\qquad j=1,2,...,k
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The conditional densities of 
\begin_inset Formula $y_{t}$
\end_inset

 given 
\begin_inset Formula $\Omega_{t-1}$
\end_inset

 are
\end_layout

\begin_layout Standard

\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none
\begin_inset Formula 
\begin{equation}
f(y_{t}|\Omega_{t-1};\theta^{(n)})=\sum_{j=1}^{k}f(y_{t}|S_{t}=j,\Omega_{t-1};\theta^{(n)})P(S_{t}=j|\Omega_{t-1};\theta^{(n)})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $f(y_{t}|S_{t},\Omega_{t-1};\theta)=\frac{1}{\sqrt{2\pi\sigma_{S_{t}}^{2}}}exp\left\{ -\frac{(y_{t}-\beta_{S_{t}})^{2}}{2\sigma_{S_{t}}^{2}}\right\} $
\end_inset

 is the likelihood function in each state for time 
\begin_inset Formula $t$
\end_inset

.
 This is simply a Gaussian probability density function.
\end_layout

\begin_layout Standard
Then, with the new observation at time 
\begin_inset Formula $t$
\end_inset

, the probabilities of each state are updated by using Bayes' rule as shown
 below
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{t};\theta^{(n)})=\frac{f(y_{t}|S_{t}=j,\Omega_{t-1};\theta^{(n)})P(S_{t}=j|\Omega_{t-1};\theta^{(n)})}{f(y_{t}|\Omega_{t-1};\theta^{(n)})}\label{eq:fProb}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
The process above is computed iteratively until all the observation is reached
 i.e., 
\begin_inset Formula $t=T$
\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Note Comment
status collapsed

\begin_layout Plain Layout
The joint conditional density function of 
\begin_inset Formula $y_{t},$
\end_inset


\begin_inset Formula $S_{t-1}$
\end_inset

and 
\begin_inset Formula $S_{t}$
\end_inset

 given 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $\Omega_{\ensuremath{t-1}}$
\end_inset


\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 are
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
f(y_{t},S_{t-1}=i,S_{t}=j|\Omega_{t-1};\theta^{(n)})=f(y_{t}|S_{t-1}=i,S_{t=}j,\Omega_{t-1};\theta^{(n)})P(S_{t-1}=i,S_{t}=j|\Omega_{t-1};\theta^{(n)})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
and 
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
P(S_{t-1}=i,S_{t}=j|\Omega_{t};\theta^{(n)})=\frac{f(y_{t},S_{t-1}=i,S_{t}=j|\Omega_{t-1};\theta^{(n)})}{f(y_{t}|\Omega_{t-1};\theta^{(n)})}
\]

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Smoothing
\end_layout

\begin_layout Standard
A smoothed probability is a probability of a non-observable Markov chain
 being in state 
\begin_inset Formula $j$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

, conditional on all available information.
 The algorithm iterates over 
\begin_inset Formula $t=T-1,T-2,...,1$
\end_inset

.
 The starting values are obtained from the final iteration of the filtered
 probabilities.
\end_layout

\begin_layout Standard
By noting that
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
P(S_{t}=j|S_{t+1}=i,\Omega_{T};\theta^{(n)}) & \thickapprox P(S_{t}=j|S_{t+1}=i,\Omega_{t};\theta^{(n)})\nonumber \\
 & =\frac{P(S_{t}=j,S_{t+1}=i|\Omega_{t};\theta^{(n)})}{P(S_{t+1}=i|\Omega_{t};\theta^{(n)})}\nonumber \\
 & =\frac{P(S_{t}=j|\Omega_{t};\theta^{(n)})p_{ij}^{(n)}}{P(S_{t+1}=i|\Omega_{t};\theta^{(n)})}
\end{align}

\end_inset


\end_layout

\begin_layout Standard
and
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{T};\theta^{(n)})=\sum_{i=1}^{k}P(S_{t}=j,S_{t+1}=i|\Omega_{T};\theta^{(n)})
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
then, the smoothed probabilities can be expressed as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
P(S_{t}=j|\Omega_{T};\theta^{(n)})=\sum_{i=1}^{k}\frac{P(S_{t+1}=i|\Omega_{T};\theta^{(n)})P(S_{t}=j|\Omega_{t};\theta^{(n)})p_{ij}^{(n)}}{P(S_{t+1}=i|\Omega_{t};\theta^{(n)})}
\end{equation}

\end_inset


\end_layout

\begin_layout Paragraph
Full log-likelihood
\end_layout

\begin_layout Standard
Once the filtered probabilities are estimated, there is enough necessary
 information to compute the full log-likelihood function.
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\ln L(\theta)=\sum_{t=1}^{T}\ln(f(y_{t}|\Omega_{t-1};\theta^{(n)})=\sum_{t=1}^{T}\ln\sum_{j=1}^{k}((f(y_{t}|S_{t}=j,\Omega_{t-1};\theta^{(n)})P(S_{t}=j|\Omega_{t-1}))\label{eq:loglik}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
This is simply a weighted average of the likelihood function in each state.
 The probabilities of states are considered as weights.
\end_layout

\begin_layout Subsubsection
M-step
\end_layout

\begin_layout Standard
The new estimated model parameters 
\begin_inset Formula $\theta^{(n+1)}$
\end_inset

 are obtained by finding a set of parameters that maximizes Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:loglik"

\end_inset

.
 This new set of parameters is more precise than the previous estimated
 value of the maximum likelihood.
 
\begin_inset Formula $\theta^{(n+1)}$
\end_inset

 serves as a set of parameters in the next iteration of the E-step.
 
\end_layout

\begin_layout Standard
Each individual parameter in 
\begin_inset Formula $\theta^{(n+1)}$
\end_inset

 are taken from its maximum value, which is determined by taking the partial
 derivative of the log-likelihood function with respect to each parameter.
 Generally, this process is similar to the standard maximum likelihood estimatio
n.
 However, it has to be weighted by the smoothed probabilities because each
 observation 
\begin_inset Formula $y_{t}$
\end_inset

 contains probability from each 
\begin_inset Formula $k$
\end_inset

 states.
 
\end_layout

\begin_layout Subsubsection
Convergence of the E-M algorithm
\end_layout

\begin_layout Standard
The E- and M-step are iteratively computed until the algorithm converges.
 The algorithm will terminate when the different between the previous and
 current estimate values is less than a specific value.
 This specific value called a 
\emph on
stopping criterion
\emph default
 needs to be specified beforehand.
 The convergence is assured since the value of the log-likelihood function
 will increase in each iteration.
 However, the E-M algorithm does not guarantee to always converge to a global
 maximum.
 The convergence of the algorithm is also likely to be only a local maxima.
 
\end_layout

\begin_layout Section
State prediction
\end_layout

\begin_layout Standard
A function to predict the most probable state for the new observation is
 implemented in 
\emph on
R
\emph default
 as an additional function in the package for this analysis (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:MSwM-Package"

\end_inset

).
\end_layout

\begin_layout Standard
The probabilities of being in state 
\begin_inset Formula $j$
\end_inset

 at time 
\begin_inset Formula $T+1$
\end_inset

 on a basis of the current information are computed by performing the filtering
 algorithm in the E-step of E-M algorithm.
 The filtered probabilities are
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
P(S_{T+1}=j|\Omega_{T+1};\theta)=\frac{f(y_{T+1}|S_{T+1}=j,\Omega_{T};\theta)P(S_{T+1}=j|\Omega_{T};\theta)}{f(y_{T+1}|\Omega_{T};\theta)}
\]

\end_inset


\end_layout

\begin_layout Standard
This is Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:fProb"

\end_inset

 where 
\begin_inset Formula $t=T+1$
\end_inset

.
 Then, the new observation at time 
\begin_inset Formula $T+1$
\end_inset

 is said to be in the state 
\begin_inset Formula $j$
\end_inset

 if it has the highest probability.
\end_layout

\begin_layout Section
Model selection
\end_layout

\begin_layout Standard
One of the most difficult tasks when modeling the Markov switching model
 is to decide on the number of states 
\begin_inset CommandInset citation
LatexCommand citep
key "rabiner1986introduction"

\end_inset

.
 The analysis will be conducted on a trial and error basis before settling
 on the most appropriate size of the model.
 In this study, several Markov switching models with different setting will
 be carried out.
 First, the number of states 
\begin_inset Formula $k$
\end_inset

 for the model will be chosen.
 Then, the number of switching coefficients in the model will be decided
 based on the selected number of states.
 Models will be selected based on the quality of the model.
 
\end_layout

\begin_layout Standard
Model selection is a task of selecting the best model for a given set of
 data.
 The Bayesian Information Criterion (BIC) is widely employed in the applied
 literature, and proved to be useful in selecting the model among a finite
 set of models (e.g., 
\begin_inset CommandInset citation
LatexCommand citet
key "leroux1992maximum"

\end_inset

 used BIC to select the number of states 
\begin_inset Formula $k$
\end_inset

).
 It is also known as Schwarz Information Criterion 
\begin_inset CommandInset citation
LatexCommand citep
key "schwarz1978estimating"

\end_inset

.
 Model which has a lower value of BIC is preferred.
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\mathrm{BIC}=-2\ln(L(\hat{\theta}))+m\cdot\ln(T)
\]

\end_inset


\end_layout

\begin_layout Standard
where 
\family roman
\series medium
\shape up
\size normal
\emph off
\bar no
\strikeout off
\uuline off
\uwave off
\noun off
\color none

\begin_inset Formula $L(\hat{\theta})$
\end_inset

 represents the maximized value of the likelihood function,
\family default
\series default
\shape default
\size default
\emph default
\bar default
\strikeout default
\uuline default
\uwave default
\noun default
\color inherit
 
\begin_inset Formula $T$
\end_inset

 is the number of observations, and 
\begin_inset Formula $m$
\end_inset

 is the number of parameters to be estimated in the model.
 While including more parameters or terms will result in a higher likelihood,
 it can also lead to an overfitting.
 BIC attempts to reduce the risk of overfitting by taking into account the
 number of parameters in the model.
 BIC can, therefore, heavily penalize a complex model.
 
\end_layout

\begin_layout Section
Non-parametric analysis
\end_layout

\begin_layout Standard
A parametric analysis outperforms a non-parametric analysis if the applied
 data belong to a known distribution family.
 However, a parametric test does not perform well in detecting change points
 of an unknown underlying distribution 
\begin_inset CommandInset citation
LatexCommand citep
key "sharkey2014nonparametric"

\end_inset

.
 Applying a non-parametric analysis to a real-world process gives a real
 advantage to the analysis.
 Data collected from a real-world process usually do not have a well-defined
 structure, which are more suitable to be applied with the non-parametric
 analysis that is not too restrictive 
\begin_inset CommandInset citation
LatexCommand citep
key "hawkins2010nonparametric"

\end_inset

.
 For this reason, the non-parametric analysis is implemented in order to
 get a rough idea of the change point location in this thesis framework.
 The obtained result is also compared with the result from using the Markov
 switching model.
\end_layout

\begin_layout Subsubsection*
E-divisive
\end_layout

\begin_layout Standard
An 
\emph on
ecp
\emph default

\begin_inset Foot
status open

\begin_layout Plain Layout
https://cran.r-project.org/web/packages/ecp/index.html
\end_layout

\end_inset

 is an extension package in 
\emph on
R
\emph default
 which mainly focuses on computing a non-parametric test for multiple change
 point analysis.
 This change point method is applicable to both univariate and multivariate
 time series.
 The fundamental idea of the package is based on the hierarchical clustering
 approach 
\begin_inset CommandInset citation
LatexCommand citep
key "james2013ecp"

\end_inset

.
 
\end_layout

\begin_layout Standard
An E-divisive method is an algorithm in the 
\emph on
ecp
\emph default
 package.
 This algorithm performs a divisive clustering in order to estimate change
 points.
 The E-divisive recursively partitions a time series and estimates a single
 change point at each iteration.
 Consequently, the new change point is located in each iteration, which
 divides the time series into different segments.
 The algorithm also uses a permutation test to compute the statistical significa
nce of an estimated change point.
 The computational time of the E-divisive algorithm is 
\begin_inset Formula $O(kT^{2})$
\end_inset

, where 
\begin_inset Formula $k$
\end_inset

 is the number of estimated change points and 
\begin_inset Formula $T$
\end_inset

 is the number of observations in the time series data.
 More details about the estimation is described in 
\begin_inset CommandInset citation
LatexCommand citet
key "matteson2014nonparametric"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Say more?....
 just wait and see
\end_layout

\end_inset


\end_layout

\begin_layout Section
Simulation study for model evaluation 
\begin_inset CommandInset label
LatexCommand label
name "sec:Simulation"

\end_inset


\end_layout

\begin_layout Standard
The state of the CPU utilization in a real data is unknown in the study.
 As a consequence, an accuracy of the Markov switching model and the E-divisive
 method cannot be computed, and the comparison between both methods can
 hardly be made.
 One possible solution to test how effective both methods are, and to verify
 how well the implemented state prediction function performs is to use a
 simulation technique.
 The dataset that consists of two predictor variables and one response variable
 with already known states is simulated.
 The actual models of each state are 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
y_{t}=\begin{cases}
\begin{array}{c}
10+0.6X_{1,t}-0.9X{}_{2,t}+0.5y_{t-1}+\varepsilon_{t}^{(1)}\\
2+0.8X_{1,t}+0.2y_{t-1}+\varepsilon_{t}^{(2)}\\
-12+0.7X_{1,t}+0.2X{}_{2.t}-0.2y_{t-1}+\varepsilon_{t}^{(3)}
\end{array} & \begin{array}{c}
\varepsilon_{t}^{(1)}\sim N(0,1);\quad\mathrm{Normal}\\
\varepsilon_{t}^{(2)}\sim N(2,0.5);\quad\mathrm{Bad}\\
\varepsilon_{t}^{(3)}\sim N(1,1);\quad\mathrm{Good}
\end{array}\end{cases}
\]

\end_inset


\end_layout

\begin_layout Standard
where, 
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $y_{t}$
\end_inset

 is assumed to be a value of a CPU usage of the time series at time 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $X_{1,t}$
\end_inset

 is a predictor variable generated by a uniform distribution on 
\begin_inset Formula $[50,200]$
\end_inset

 of the time series at time 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
\begin_inset Formula $X_{2,t}$
\end_inset

 is a predictor variable generated by a uniform distribution on 
\begin_inset Formula $[0,50]$
\end_inset

 of the time series at time 
\begin_inset Formula $t$
\end_inset


\end_layout

\begin_layout Standard
There are two simulated datasets – Dataset 1 and Dataset 2 – and each of
 them contains 500 observations.
 Both datasets have different time periods where the switches between states
 occur.
 The simulated Dataset 1 has a longer duration to remain in its own state
 before switching to the other states than the simulated Dataset 2.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sim_data"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "sim_data2"

\end_inset

 present plots of 
\begin_inset Formula $y$
\end_inset

 over a period of time, and the period where observations in the data belong
 to one of the states for the first and second simulated data, respectively.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/sim1.png
	lyxscale 50
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\emph on
Top:
\emph default
 A simulated data of Dataset 1 where 
\begin_inset Formula $y$
\end_inset

 variable is the response variable.
 
\emph on
Bottom:
\emph default
 The period in the time series when observation is in each state.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sim_data"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
placement H
wide false
sideways false
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Graphics
	filename picture/sim2.png
	lyxscale 50
	scale 35

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout

\emph on
Top:
\emph default
 A simulated data of Dataset 2 where 
\begin_inset Formula $y$
\end_inset

 variable is the response variable.
 
\emph on
Bottom:
\emph default
 The period in the time series when observation is in each state.
\end_layout

\end_inset


\begin_inset CommandInset label
LatexCommand label
name "sim_data2"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Technical aspects
\end_layout

\begin_layout Standard
The thesis work has been carried out using the 
\emph on
R
\emph default
 programming language for the purpose of data cleaning, preprocessing, and
 analysis.
 The Markov switching model was performed using the 
\emph on
MSwM
\emph default
 package.
 Various extensions and modifications were implemented in the package e.g.,
 handling predictor categorical variables, the state prediction function,
 and plots for visualizing the results (More details can be found in 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:MSwM-Package"

\end_inset

).
 For the E-divisive method, the 
\emph on
ecp
\emph default
 package was used.
 
\end_layout

\begin_layout Standard
\begin_inset Branch NoChildDocument
status collapsed

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "thesisExample"
options "alpha"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset nomencl_print
LatexCommand printnomenclature
set_width "custom"
width "2.5cm"

\end_inset


\end_layout

\end_inset


\end_layout

\end_body
\end_document
